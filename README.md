# Part-Of-Speech Tagging Using Hidden Markov Chain Model
Part-Of-Speech(POS) tagging is a significant research area in Natural Language Processing. In detail, it represents the process of assigning a part-of-speech marker to each word in an input text. Word is ambiguous, for an individual word can have more than one possible tags. Therefore, one of the most challenging tasks of POS tagging is finding the correct tags for ambiguous words.

A good news is that, for some of ambiguous words, different tags are not equally likely. Letâ€™s take a as an example, the POS of a could be a Proper Noun (NNP) or Determiner (DT). However, in the emit matrix we calculated on our training data, the probability of DT is 20.1%, but NNP is only 0.00076%, which indicated that the DT is much more likely.

Due to this property, we can easily build a baseline model for POS tagging task: given an ambiguous word, choose the tag which is most frequent in the training corpus[1]. This most-frequent-tag baseline model performs quite good on our data set, it achieves an accuracy of 94.68% on our test set 1, and 91.67% on test set 2. However, this accuracy is still far away from that could have been achieved by more advanced models. Therefore, in this project, I try to use Hidden Markov Chain Model, which is introduced in the lecture to do POS tagging. The efforts I take to achieve this goal is as follows:
1. Extract emit and transition parameters from the training set.
2. Bulid the most-frequent-tag baseline model to tag the words in our test sets.
3. Build Viterbi and Forward algorithm from scratch in R studio to tag the words. 
4. Analyze, evaluate and compare the predictions generated by each model.

The detailed introduction and proof is shown in project report.
