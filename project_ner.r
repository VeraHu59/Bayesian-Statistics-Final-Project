#### STAT 927 Final Project ####
#### Penn ID: 26924539 ####

## Part 1: Data Preparation ##
# read in data and do some data cleaning

# emit is the emit matrix generated by training data
emit <- read.csv("~/Desktop/927 Project/NER/ner_emit.csv")
# word is all the word appear in train data
word <- as.character(emit$X)
# rename the columns
colnames(emit)[16]<-"``"
colnames(emit)[23]<-","
colnames(emit)[29]<-":"
colnames(emit)[39]<-"$"
colnames(emit)[41]<-";"
colnames(emit)[31]<-"WP$"
colnames(emit)[25]<-"PRP$"

# transition is the transition matrix generated by training data
transition <- read.csv("~/Desktop/927 Project/NER/ner_transition.csv")
# pos is all the states(POS) we have
pos <- as.character(transition$X)
pos[9] <-","

# rename the columns 
colnames(transition)[16]<-"``"
colnames(transition)[23]<-","
colnames(transition)[29]<-":"
colnames(transition)[39]<-"$"
colnames(transition)[41]<-";"
colnames(transition)[31]<-"WP$"
colnames(transition)[25]<-"PRP$"

# import initial transition matrix
transition.initial <- read.csv("~/Desktop/927 Project/NER/ner_initial_transition.csv", header=FALSE)
initial.pos <- as.character(transition.initial$V1)
initial.prob <- as.character(transition.initial$V2)

# import test data
test <- read.delim("~/Desktop/927 Project/NER/ner_test.txt", header=FALSE)
test.word <- as.character(test$V1)
test.pos <- as.character(test$V2)

# m is the total number of hidden states (# of unique pos)
m <- length(pos)

# count how many words in test data appear in our train data
count <- 0
for(i in 1:length(test.word)){
  if(test.word[i] %in% word){
    count <- count+ 1}
  else{
    print(test.word[i])
  }
}
print(count/length(test.word))

# keep words in test data that also appear in our train data
test.word.selected <- c()
test.pos.selected <- c()
for(i in 1:length(test.word)){
  if(test.word[i] %in% word){
    test.word.selected  <- c(test.word.selected,test.word[i])
    test.pos.selected <- c(test.pos.selected, test.pos[i])}
}
# n is the total number of word we need to tag
n <- length(test.word.selected)

## Part 2: Data Exploration ##
install.packages('plotrix')
library(plotrix)
pie3D(as.numeric(initial.prob), labels=initial.pos,, explode = 0.1, main = "The Pie Chart of POS Tags")

## Part 3: Baseline Model##
# tag the word with the POS that has the highest emit probability
pos.pred <- c()
for(i in 1:n){
  row = match(test.word.selected[i],word)
  col = which(emit[row,][2:43]==max(emit[row,][2:43]))
  pos.pred <- c(pos.pred, colnames(emit)[col+1])
}

evaluate <- function(result){
  correct <- 0
  for(i in 1:length(result)){
    if(result[i]==test.pos.selected[i]){
      correct <- correct+1
    }
  }
  accuracy <- correct/length(result)
  print(accuracy)
}

evaluate(pos.pred)

## Part 4: VITERBI ALGORITHM  ##

# given the current observed word and state (pos), return the emission probability
emit.prob <- function(obs,state){
  row <- which(word==obs)
  col <- match(state,colnames(emit))
  out <- emit[row,col]
  return(out)
}

# given the current and previous pos, return the transition probability
transition.prob <- function(state.prev, state.curr){
  # if this is not the initial step
  if(state.prev!="Null"){
    columns <- colnames(transition)
    row <- match(state.prev,pos)
    col <- match(state.curr,columns)
    return(transition[row,col])
  }else{
    index = which(initial.pos==state.curr)
    return(as.numeric(initial.prob[index]))
  }
}

viterbi <- function(test.temp){
  n  <-length(test.temp)
  delta <- matrix(NA,nrow=n,ncol=m)
  # Initialization:
  for (i in 1:m){
    delta[1,i] <- emit.prob(test.temp[1],pos[i])*transition.prob("Null",pos[i])
  }
  # if there are at least two words in the chunk
  if(n!=1){
    # Recursion:
    for (t in 2:n){
      for (i in 1:m){
        temp <- rep(NA,m)
        state.curr <- pos[i]
        for (j in 1:m){
          # state is the jth state
          state.prev <- pos[j]
          temp[j] <- delta[t-1,j]*emit.prob(test.temp[t],state.curr)*transition.prob(state.prev, state.curr)
        }
        delta[t,i] <- max(temp, na.rm = TRUE)
      }
    }
    # Tracing Back:
    tag <- rep(NA,n)
    tag[n] <- which(delta[n,]==max(delta[n,]))
    for (t in (n-1):1){
      temp <- rep(NA,m)
      for (j in 1:m){
        state.prev <- pos[j]
        state.curr <- pos[tag[t+1]]
        temp[j] <- delta[t,j]*transition.prob(state.prev,state.curr)
      }
      tag[t] <- which(temp==max(temp, na.rm = TRUE))
    }
    # transfer the tag index into real POS
    pos.pred <- c()
    for (i in 1:n){
      pos.pred <- c(pos.pred, pos[tag[i]])
    }
    return(pos.pred)
  }
  else{
    # if there is only 1 word in the chunk
    tag <- which(delta[1,]==max(delta[1,]))
    return(pos[tag])
  }
}

# break test data into chunks seperated by "." and run the viterbi algorithm
test.temp <- c()
result.viterbi <- c()
for(i in 1:length(test.word.selected)){
  if (test.word.selected[i] != "." ){
    test.temp <- c(test.temp, test.word.selected[i])
  }else{
    test.temp <- c(test.temp, test.word.selected[i])
    print(test.temp)
    result.viterbi <- c(result.viterbi, viterbi(test.temp))
    test.temp <- c()
  }
}
# Evaluate the predicted POS
evaluate(result.viterbi)

# save the predict results of viterbi algorithm
d <- data.frame( test.word.selected, test.pos.selected,result.viterbi,  stringsAsFactors=FALSE )
write.table(d, "~/Desktop/927 Project/NER/viterbi_result.csv" )

## Part 5: FORWARD ALGORITHM ## 

numsamp <- 5
# select the most possible tag from X.samp
forward.select <-function(X){
  n <- length(X[1,])
  result <- c()
  for(i in 1:n){
    tag <- as.character(as.data.frame(table(X[,i]))$Var1)
    freq <- as.numeric(as.character(as.data.frame(table(X[,i]))$Freq))
    tag.max <- as.numeric(tag[which(freq==max(freq))])
    result[i] <- pos[tag.max]
  }
  return(result)
}

# sample the tag from X.samp, more uncertainty
forward.sample <- function(X){
  n <- length(X[1,])
  result <- c()
  for (i in 1:n){
    result[i] <- sample(X[,i],size=1)
  }
  return(result)
}

# return the tags of given test word
forward <- function(test.temp){
  n <- length(test.temp)
  X.samp <- matrix(NA,nrow=numsamp,ncol=n)
  for (iter in 1:numsamp){
    # Forward Algorithm 
    alpha <- matrix(NA,nrow=n,ncol=m)
    for (i in 1:m){
      alpha[1,i] <- emit.prob(test.temp[1],pos[i])*transition.prob("Null",pos[i])
    }
    if(n==1){
      probvec <- alpha[1,]/sum(alpha[1,])
      tag <- sample(1:m,size=1,prob=probvec)
      X.samp[iter,] <- tag
    }else{
      for (t in 2:n){
        for (i in 1:m){
          state.curr <- pos[i]
          temp <- rep(NA,m)
          for (j in 1:m){
            state.prev <- pos[j]
            temp[j] <- alpha[t-1,j]*emit.prob(test.temp[t],state.curr)*transition.prob(state.prev, state.curr)
          }
          alpha[t,i] <- sum(temp)
        }
      }
      # Backwards Sampling 
      tag <- rep(NA,n)
      probvec <- alpha[n,]/sum(alpha[n,])
      tag[n] <- sample(1:m,size=1,prob=probvec)
      for (t in (n-1):1){
        probvec <- rep(NA,m)
        for (i in 1:m){
          state.prev <- pos[i]
          state.curr <- pos[tag[t+1]]
          probvec[i] <- alpha[t,i]*transition.prob(state.prev,state.curr)
        }
        probvec <- probvec/sum(probvec)
        tag[t] <- sample(1:m,size=1,prob=probvec)
      }
      X.samp[iter,] <- tag
    }
  }
  result <- forward.select(X.samp)
  print(result)
  return(result)
}

# break test data into chunks seperated by "." and run the forward algorithm
test.temp <- c()
result.forward <- c()
for(i in 1:length(test.word.selected)){
  if (test.word.selected[i] != "."){
    test.temp <- c(test.temp, test.word.selected[i])
  }else{
    test.temp <- c(test.temp, test.word.selected[i])
    result.forward <- c(result.forward, forward(test.temp))
    test.temp <- c()
  }
}

# Evaluate the predicted POS
evaluate(result.forward)

# save the predict results of forward algorithm
d <- data.frame(test.word.selected, test.pos.selected,result.forward,  stringsAsFactors=FALSE )
write.table(d, "~/Desktop/927 Project/NER/forward_result.csv" )

## Part 6: New Test Data ##
# import a larger data set
test2 <- read.delim("~/Desktop/927 Project/NER/ner_test_2.txt", header=FALSE)
test2.word <- as.character(test2$V1)
test2.pos <- as.character(test2$V2)

count <- 0
for(i in 1:length(test2.word)){
  if(test2.word[i] %in% word){
    count <- count+ 1}
  else{
    print(test2.word[i])
  }
}
print(count/length(test2.word))

# keep words in test data that also appear in our train data
test2.word.selected <- c()
test2.pos.selected <- c()
for(i in 1:length(test2.word)){
  if(test2.word[i] %in% word){
    test2.word.selected  <- c(test2.word.selected,test2.word[i])
    test2.pos.selected <- c(test2.pos.selected, test2.pos[i])}
}

# n is the total number of word we need to tag
n <- length(test2.word.selected)

# run viterbi again on new test data
test.temp <- c()
result2.viterbi <- c()
for(i in 1:length(test2.word.selected)){
  if (test2.word.selected[i] != "." ){
    test.temp <- c(test.temp, test2.word.selected[i])
  }else{
    test.temp <- c(test.temp, test2.word.selected[i])
    # print(test.temp)
    result2.viterbi <- c(result2.viterbi, viterbi(test.temp))
    test.temp <- c()
  }
}

# Evaluate the predicted POS
evaluate2 <- function(result){
  correct <- 0
  for(i in 1:length(result)){
    if(result[i]==test2.pos.selected[i]){
      correct <- correct+1
    }
  }
  accuracy <- correct/length(result)
  print(accuracy)
}

evaluate2(result2.viterbi)

# save the predict results of viterbi algorithm
d <- data.frame( test2.word.selected, test2.pos.selected,result2.viterbi,  stringsAsFactors=FALSE )
write.table(d, "~/Desktop/927 Project/NER/viterbi_result_2.csv" )

# run forward algorithm again on new test data
test.temp <- c()
result2.forward <- c()
for(i in 1:length(test2.word.selected)){
  if (test2.word.selected[i] != "."){
    test.temp <- c(test.temp, test2.word.selected[i])
  }else{
    test.temp <- c(test.temp, test2.word.selected[i])
    result2.forward <- c(result2.forward, forward(test.temp))
    test.temp <- c()
  }
}

# Evaluate the predicted POS
evaluate2(result2.forward)

# save the predict results of forward algorithm
d <- data.frame(test2.word.selected, test2.pos.selected,result2.forward,  stringsAsFactors=FALSE )
write.table(d, "~/Desktop/927 Project/NER/forward_result_2.csv" )

# Baseline Model
pos.pred <- c()
for(i in 1:n){
  row = match(test2.word.selected[i],word)
  col = which(emit[row,][2:43]==max(emit[row,][2:43]))
  pos.pred <- c(pos.pred, colnames(emit)[col+1])
}

evaluate2(pos.pred)

